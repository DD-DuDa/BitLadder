{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ddy/miniconda3/envs/bitdecode/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "import triton\n",
    "\n",
    "import numpy as np\n",
    "import bit_decode_cuda as bit_decode_cuda\n",
    "from bit_decode import kvcache_pack_int, fwd_kvcache_int\n",
    "from bit_decode import DynamicCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_ref(\n",
    "    q,\n",
    "    k,\n",
    "    v,\n",
    "):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        q: (batch_size, seqlen_q, nheads, head_dim)\n",
    "        k: (batch_size, seqlen_k, nheads_k, head_dim)\n",
    "        v: (batch_size, seqlen_k, nheads_k, head_dim)\n",
    "    Output:\n",
    "        output: (batch_size, seqlen_q, nheads, head_dim)\n",
    "        attention: (batch_size, nheads, seqlen_q, seqlen_k), softmax after dropout\n",
    "    \"\"\"\n",
    "    dtype_og = q.dtype\n",
    "\n",
    "    d = q.shape[-1]\n",
    "\n",
    "    scores = torch.einsum(\"bthd,bshd->bhts\", q / math.sqrt(d), k)\n",
    "    \n",
    "    attention = torch.softmax(scores, dim=-1).to(v.dtype)\n",
    "\n",
    "    output = torch.einsum(\"bhts,bshd->bthd\", attention, v)\n",
    "\n",
    "    return output.to(dtype=dtype_og), attention.to(dtype=dtype_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantization parameters\n",
    "quant_mode = \"k-channel\"\n",
    "num_bits = 4\n",
    "pack_nums = 16 / num_bits\n",
    "group_size = 32\n",
    "residual_block_size = 128\n",
    "\n",
    "device = \"cuda\"\n",
    "dtype = torch.float16\n",
    "\n",
    "layer_idx = 0\n",
    "batch_size = 1\n",
    "nheads = 32\n",
    "nheads_k = 32\n",
    "d = 128\n",
    "\n",
    "seqlen_q = 1\n",
    "seqlen_k = 1024\n",
    "sm_scale = 1.0 / math.sqrt(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 2: bitdecode vs pytorch: 0.0027313232421875\n",
      "Round 3: bitdecode vs pytorch: 0.002727508544921875\n",
      "Round 4: bitdecode vs pytorch: 0.0027256011962890625\n",
      "Round 5: bitdecode vs pytorch: 0.0027217864990234375\n",
      "Round 6: bitdecode vs pytorch: 0.002719879150390625\n",
      "Round 7: bitdecode vs pytorch: 0.0027179718017578125\n",
      "Round 8: bitdecode vs pytorch: 0.0027141571044921875\n",
      "Round 9: bitdecode vs pytorch: 0.002712249755859375\n",
      "Round 10: bitdecode vs pytorch: 0.00270843505859375\n",
      "Round 11: bitdecode vs pytorch: 0.0027065277099609375\n",
      "Round 12: bitdecode vs pytorch: 0.0027027130126953125\n",
      "Round 13: bitdecode vs pytorch: 0.0027008056640625\n",
      "Round 14: bitdecode vs pytorch: 0.002696990966796875\n",
      "Round 15: bitdecode vs pytorch: 0.0026950836181640625\n",
      "Round 16: bitdecode vs pytorch: 0.00269317626953125\n",
      "Round 17: bitdecode vs pytorch: 0.0026912689208984375\n",
      "Round 18: bitdecode vs pytorch: 0.0026874542236328125\n",
      "Round 19: bitdecode vs pytorch: 0.002685546875\n",
      "Round 20: bitdecode vs pytorch: 0.002681732177734375\n",
      "Round 21: bitdecode vs pytorch: 0.0026798248291015625\n",
      "Round 22: bitdecode vs pytorch: 0.00267791748046875\n",
      "Round 23: bitdecode vs pytorch: 0.0026760101318359375\n",
      "Round 24: bitdecode vs pytorch: 0.0026721954345703125\n",
      "Round 25: bitdecode vs pytorch: 0.0026702880859375\n",
      "Round 26: bitdecode vs pytorch: 0.0026683807373046875\n",
      "Round 27: bitdecode vs pytorch: 0.0026645660400390625\n",
      "Round 28: bitdecode vs pytorch: 0.00266265869140625\n",
      "Round 29: bitdecode vs pytorch: 0.002658843994140625\n",
      "Round 30: bitdecode vs pytorch: 0.0026569366455078125\n",
      "Round 31: bitdecode vs pytorch: 0.002655029296875\n",
      "Round 32: bitdecode vs pytorch: 0.0026531219482421875\n",
      "Round 33: bitdecode vs pytorch: 0.0026493072509765625\n",
      "Round 34: bitdecode vs pytorch: 0.00264739990234375\n",
      "Round 35: bitdecode vs pytorch: 0.0026454925537109375\n",
      "Round 36: bitdecode vs pytorch: 0.0026416778564453125\n",
      "Round 37: bitdecode vs pytorch: 0.0026397705078125\n",
      "Round 38: bitdecode vs pytorch: 0.0026378631591796875\n",
      "Round 39: bitdecode vs pytorch: 0.002635955810546875\n",
      "Round 40: bitdecode vs pytorch: 0.0026340484619140625\n",
      "Round 41: bitdecode vs pytorch: 0.0026302337646484375\n",
      "Round 42: bitdecode vs pytorch: 0.002628326416015625\n",
      "Round 43: bitdecode vs pytorch: 0.0026264190673828125\n",
      "Round 44: bitdecode vs pytorch: 0.00262451171875\n",
      "Round 45: bitdecode vs pytorch: 0.002620697021484375\n",
      "Round 46: bitdecode vs pytorch: 0.0026187896728515625\n",
      "Round 47: bitdecode vs pytorch: 0.0026149749755859375\n",
      "Round 48: bitdecode vs pytorch: 0.002613067626953125\n",
      "Round 49: bitdecode vs pytorch: 0.0026092529296875\n",
      "Round 50: bitdecode vs pytorch: 0.0026073455810546875\n",
      "Round 51: bitdecode vs pytorch: 0.002605438232421875\n",
      "Round 52: bitdecode vs pytorch: 0.0026035308837890625\n",
      "Round 53: bitdecode vs pytorch: 0.0025997161865234375\n",
      "Round 54: bitdecode vs pytorch: 0.002597808837890625\n",
      "Round 55: bitdecode vs pytorch: 0.0025959014892578125\n",
      "Round 56: bitdecode vs pytorch: 0.002593994140625\n",
      "Round 57: bitdecode vs pytorch: 0.002590179443359375\n",
      "Round 58: bitdecode vs pytorch: 0.0025882720947265625\n",
      "Round 59: bitdecode vs pytorch: 0.00258636474609375\n",
      "Round 60: bitdecode vs pytorch: 0.002582550048828125\n",
      "Round 61: bitdecode vs pytorch: 0.0025806427001953125\n",
      "Round 62: bitdecode vs pytorch: 0.0025787353515625\n",
      "Round 63: bitdecode vs pytorch: 0.002574920654296875\n",
      "Round 64: bitdecode vs pytorch: 0.0025730133056640625\n",
      "Round 65: bitdecode vs pytorch: 0.00257110595703125\n",
      "Round 66: bitdecode vs pytorch: 0.0025691986083984375\n",
      "Round 67: bitdecode vs pytorch: 0.0025653839111328125\n",
      "Round 68: bitdecode vs pytorch: 0.0025634765625\n",
      "Round 69: bitdecode vs pytorch: 0.0025615692138671875\n",
      "Round 70: bitdecode vs pytorch: 0.002559661865234375\n",
      "Round 71: bitdecode vs pytorch: 0.0025577545166015625\n",
      "Round 72: bitdecode vs pytorch: 0.0025539398193359375\n",
      "Round 73: bitdecode vs pytorch: 0.002552032470703125\n",
      "Round 74: bitdecode vs pytorch: 0.0025501251220703125\n",
      "Round 75: bitdecode vs pytorch: 0.0025482177734375\n",
      "Round 76: bitdecode vs pytorch: 0.002544403076171875\n",
      "Round 77: bitdecode vs pytorch: 0.0025424957275390625\n",
      "Round 78: bitdecode vs pytorch: 0.00254058837890625\n",
      "Round 79: bitdecode vs pytorch: 0.0025386810302734375\n",
      "Round 80: bitdecode vs pytorch: 0.002536773681640625\n",
      "Round 81: bitdecode vs pytorch: 0.002532958984375\n",
      "Round 82: bitdecode vs pytorch: 0.0025310516357421875\n",
      "Round 83: bitdecode vs pytorch: 0.002529144287109375\n",
      "Round 84: bitdecode vs pytorch: 0.0025272369384765625\n",
      "Round 85: bitdecode vs pytorch: 0.00252532958984375\n",
      "Round 86: bitdecode vs pytorch: 0.0025234222412109375\n",
      "Round 87: bitdecode vs pytorch: 0.002521514892578125\n",
      "Round 88: bitdecode vs pytorch: 0.0025196075439453125\n",
      "Round 89: bitdecode vs pytorch: 0.0025177001953125\n",
      "Round 90: bitdecode vs pytorch: 0.002513885498046875\n",
      "Round 91: bitdecode vs pytorch: 0.0025119781494140625\n",
      "Round 92: bitdecode vs pytorch: 0.00251007080078125\n",
      "Round 93: bitdecode vs pytorch: 0.002506256103515625\n",
      "Round 94: bitdecode vs pytorch: 0.0025043487548828125\n",
      "Round 95: bitdecode vs pytorch: 0.00250244140625\n",
      "Round 96: bitdecode vs pytorch: 0.0025005340576171875\n",
      "Round 97: bitdecode vs pytorch: 0.002498626708984375\n",
      "Round 98: bitdecode vs pytorch: 0.0024967193603515625\n",
      "Round 99: bitdecode vs pytorch: 0.0024929046630859375\n",
      "Round 100: bitdecode vs pytorch: 0.002490997314453125\n",
      "Round 101: bitdecode vs pytorch: 0.0024890899658203125\n",
      "Round 102: bitdecode vs pytorch: 0.0024871826171875\n",
      "Round 103: bitdecode vs pytorch: 0.0024852752685546875\n",
      "Round 104: bitdecode vs pytorch: 0.0024814605712890625\n",
      "Round 105: bitdecode vs pytorch: 0.00247955322265625\n",
      "Round 106: bitdecode vs pytorch: 0.0024776458740234375\n",
      "Round 107: bitdecode vs pytorch: 0.002475738525390625\n",
      "Round 108: bitdecode vs pytorch: 0.0024738311767578125\n",
      "Round 109: bitdecode vs pytorch: 0.0024700164794921875\n",
      "Round 110: bitdecode vs pytorch: 0.002468109130859375\n",
      "Round 111: bitdecode vs pytorch: 0.0024662017822265625\n",
      "Round 112: bitdecode vs pytorch: 0.00246429443359375\n",
      "Round 113: bitdecode vs pytorch: 0.0024623870849609375\n",
      "Round 114: bitdecode vs pytorch: 0.002460479736328125\n",
      "Round 115: bitdecode vs pytorch: 0.0024566650390625\n",
      "Round 116: bitdecode vs pytorch: 0.0024547576904296875\n",
      "Round 117: bitdecode vs pytorch: 0.002452850341796875\n",
      "Round 118: bitdecode vs pytorch: 0.0024509429931640625\n",
      "Round 119: bitdecode vs pytorch: 0.00244903564453125\n",
      "Round 120: bitdecode vs pytorch: 0.0024471282958984375\n",
      "Round 121: bitdecode vs pytorch: 0.002445220947265625\n",
      "Round 122: bitdecode vs pytorch: 0.00244140625\n",
      "Round 123: bitdecode vs pytorch: 0.0024394989013671875\n",
      "Round 124: bitdecode vs pytorch: 0.002437591552734375\n",
      "Round 125: bitdecode vs pytorch: 0.0024356842041015625\n",
      "Round 126: bitdecode vs pytorch: 0.00243377685546875\n",
      "Round 127: bitdecode vs pytorch: 0.0024318695068359375\n",
      "Round 128: bitdecode vs pytorch: 0.002429962158203125\n",
      "Round 129: bitdecode vs pytorch: 0.0024280548095703125\n",
      "Round 130: bitdecode vs pytorch: 0.0025577545166015625\n",
      "Round 131: bitdecode vs pytorch: 0.00255584716796875\n",
      "Round 132: bitdecode vs pytorch: 0.0025539398193359375\n",
      "Round 133: bitdecode vs pytorch: 0.002552032470703125\n",
      "Round 134: bitdecode vs pytorch: 0.0025501251220703125\n",
      "Round 135: bitdecode vs pytorch: 0.0025463104248046875\n",
      "Round 136: bitdecode vs pytorch: 0.002544403076171875\n",
      "Round 137: bitdecode vs pytorch: 0.00254058837890625\n",
      "Round 138: bitdecode vs pytorch: 0.0025386810302734375\n",
      "Round 139: bitdecode vs pytorch: 0.0025386810302734375\n",
      "Round 140: bitdecode vs pytorch: 0.0025348663330078125\n",
      "Round 141: bitdecode vs pytorch: 0.002532958984375\n",
      "Round 142: bitdecode vs pytorch: 0.0025310516357421875\n",
      "Round 143: bitdecode vs pytorch: 0.002529144287109375\n",
      "Round 144: bitdecode vs pytorch: 0.0025272369384765625\n",
      "Round 145: bitdecode vs pytorch: 0.0025234222412109375\n",
      "Round 146: bitdecode vs pytorch: 0.002521514892578125\n",
      "Round 147: bitdecode vs pytorch: 0.0025196075439453125\n",
      "Round 148: bitdecode vs pytorch: 0.0025177001953125\n",
      "Round 149: bitdecode vs pytorch: 0.0025157928466796875\n",
      "Round 150: bitdecode vs pytorch: 0.002513885498046875\n",
      "Round 151: bitdecode vs pytorch: 0.0025119781494140625\n",
      "Round 152: bitdecode vs pytorch: 0.00251007080078125\n",
      "Round 153: bitdecode vs pytorch: 0.002506256103515625\n",
      "Round 154: bitdecode vs pytorch: 0.0025043487548828125\n",
      "Round 155: bitdecode vs pytorch: 0.00250244140625\n",
      "Round 156: bitdecode vs pytorch: 0.0025005340576171875\n",
      "Round 157: bitdecode vs pytorch: 0.002498626708984375\n",
      "Round 158: bitdecode vs pytorch: 0.00249481201171875\n",
      "Round 159: bitdecode vs pytorch: 0.0024929046630859375\n",
      "Round 160: bitdecode vs pytorch: 0.002490997314453125\n",
      "Round 161: bitdecode vs pytorch: 0.0024890899658203125\n",
      "Round 162: bitdecode vs pytorch: 0.0024871826171875\n",
      "Round 163: bitdecode vs pytorch: 0.0024852752685546875\n",
      "Round 164: bitdecode vs pytorch: 0.002483367919921875\n",
      "Round 165: bitdecode vs pytorch: 0.0024814605712890625\n",
      "Round 166: bitdecode vs pytorch: 0.00247955322265625\n",
      "Round 167: bitdecode vs pytorch: 0.0024776458740234375\n",
      "Round 168: bitdecode vs pytorch: 0.002475738525390625\n",
      "Round 169: bitdecode vs pytorch: 0.0024738311767578125\n",
      "Round 170: bitdecode vs pytorch: 0.002471923828125\n",
      "Round 171: bitdecode vs pytorch: 0.0024700164794921875\n",
      "Round 172: bitdecode vs pytorch: 0.002468109130859375\n",
      "Round 173: bitdecode vs pytorch: 0.0024662017822265625\n",
      "Round 174: bitdecode vs pytorch: 0.00246429443359375\n",
      "Round 175: bitdecode vs pytorch: 0.0024623870849609375\n",
      "Round 176: bitdecode vs pytorch: 0.002460479736328125\n",
      "Round 177: bitdecode vs pytorch: 0.0024585723876953125\n",
      "Round 178: bitdecode vs pytorch: 0.0024566650390625\n",
      "Round 179: bitdecode vs pytorch: 0.002452850341796875\n",
      "Round 180: bitdecode vs pytorch: 0.0024509429931640625\n",
      "Round 181: bitdecode vs pytorch: 0.00244903564453125\n",
      "Round 182: bitdecode vs pytorch: 0.0024471282958984375\n",
      "Round 183: bitdecode vs pytorch: 0.002445220947265625\n",
      "Round 184: bitdecode vs pytorch: 0.0024433135986328125\n",
      "Round 185: bitdecode vs pytorch: 0.00244140625\n",
      "Round 186: bitdecode vs pytorch: 0.0024394989013671875\n",
      "Round 187: bitdecode vs pytorch: 0.002437591552734375\n",
      "Round 188: bitdecode vs pytorch: 0.0024356842041015625\n",
      "Round 189: bitdecode vs pytorch: 0.00243377685546875\n",
      "Round 190: bitdecode vs pytorch: 0.0024318695068359375\n",
      "Round 191: bitdecode vs pytorch: 0.002429962158203125\n",
      "Round 192: bitdecode vs pytorch: 0.0024261474609375\n",
      "Round 193: bitdecode vs pytorch: 0.0024261474609375\n",
      "Round 194: bitdecode vs pytorch: 0.0024242401123046875\n",
      "Round 195: bitdecode vs pytorch: 0.002422332763671875\n",
      "Round 196: bitdecode vs pytorch: 0.0024204254150390625\n",
      "Round 197: bitdecode vs pytorch: 0.00241851806640625\n",
      "Round 198: bitdecode vs pytorch: 0.0024166107177734375\n",
      "Round 199: bitdecode vs pytorch: 0.002414703369140625\n",
      "Round 200: bitdecode vs pytorch: 0.0024127960205078125\n",
      "Round 201: bitdecode vs pytorch: 0.002410888671875\n",
      "Round 202: bitdecode vs pytorch: 0.0024089813232421875\n",
      "Round 203: bitdecode vs pytorch: 0.0024089813232421875\n",
      "Round 204: bitdecode vs pytorch: 0.002407073974609375\n",
      "Round 205: bitdecode vs pytorch: 0.00240325927734375\n",
      "Round 206: bitdecode vs pytorch: 0.0024013519287109375\n",
      "Round 207: bitdecode vs pytorch: 0.002399444580078125\n",
      "Round 208: bitdecode vs pytorch: 0.0023975372314453125\n",
      "Round 209: bitdecode vs pytorch: 0.0023956298828125\n",
      "Round 210: bitdecode vs pytorch: 0.0023937225341796875\n",
      "Round 211: bitdecode vs pytorch: 0.002391815185546875\n",
      "Round 212: bitdecode vs pytorch: 0.00238800048828125\n",
      "Round 213: bitdecode vs pytorch: 0.0023860931396484375\n",
      "Round 214: bitdecode vs pytorch: 0.002384185791015625\n",
      "Round 215: bitdecode vs pytorch: 0.0023822784423828125\n",
      "Round 216: bitdecode vs pytorch: 0.0023822784423828125\n",
      "Round 217: bitdecode vs pytorch: 0.0023784637451171875\n",
      "Round 218: bitdecode vs pytorch: 0.002376556396484375\n",
      "Round 219: bitdecode vs pytorch: 0.0023746490478515625\n",
      "Round 220: bitdecode vs pytorch: 0.00237274169921875\n",
      "Round 221: bitdecode vs pytorch: 0.0023708343505859375\n",
      "Round 222: bitdecode vs pytorch: 0.002368927001953125\n",
      "Round 223: bitdecode vs pytorch: 0.0023670196533203125\n",
      "Round 224: bitdecode vs pytorch: 0.0023651123046875\n",
      "Round 225: bitdecode vs pytorch: 0.0023632049560546875\n",
      "Round 226: bitdecode vs pytorch: 0.002361297607421875\n",
      "Round 227: bitdecode vs pytorch: 0.0023593902587890625\n",
      "Round 228: bitdecode vs pytorch: 0.00235748291015625\n",
      "Round 229: bitdecode vs pytorch: 0.0023555755615234375\n",
      "Round 230: bitdecode vs pytorch: 0.002353668212890625\n",
      "Round 231: bitdecode vs pytorch: 0.0023517608642578125\n",
      "Round 232: bitdecode vs pytorch: 0.002349853515625\n",
      "Round 233: bitdecode vs pytorch: 0.0023479461669921875\n",
      "Round 234: bitdecode vs pytorch: 0.002346038818359375\n",
      "Round 235: bitdecode vs pytorch: 0.0023441314697265625\n",
      "Round 236: bitdecode vs pytorch: 0.00234222412109375\n",
      "Round 237: bitdecode vs pytorch: 0.0023403167724609375\n",
      "Round 238: bitdecode vs pytorch: 0.002338409423828125\n",
      "Round 239: bitdecode vs pytorch: 0.0023365020751953125\n",
      "Round 240: bitdecode vs pytorch: 0.0023345947265625\n",
      "Round 241: bitdecode vs pytorch: 0.0023345947265625\n",
      "Round 242: bitdecode vs pytorch: 0.0023326873779296875\n",
      "Round 243: bitdecode vs pytorch: 0.0023288726806640625\n",
      "Round 244: bitdecode vs pytorch: 0.0023288726806640625\n",
      "Round 245: bitdecode vs pytorch: 0.0023250579833984375\n",
      "Round 246: bitdecode vs pytorch: 0.002323150634765625\n",
      "Round 247: bitdecode vs pytorch: 0.0023212432861328125\n",
      "Round 248: bitdecode vs pytorch: 0.0023193359375\n",
      "Round 249: bitdecode vs pytorch: 0.0023174285888671875\n",
      "Round 250: bitdecode vs pytorch: 0.002315521240234375\n",
      "Round 251: bitdecode vs pytorch: 0.0023136138916015625\n"
     ]
    }
   ],
   "source": [
    "####### Round 1 : Prefill #######\n",
    "torch.manual_seed(42)\n",
    "\n",
    "q = torch.rand(batch_size, seqlen_q, nheads, d, device=device, dtype=dtype)\n",
    "k_state = torch.randn(batch_size, seqlen_k, nheads_k, d, device=device, dtype=dtype)\n",
    "v_state = torch.randn(batch_size, seqlen_k, nheads_k, d, device=device, dtype=dtype)\n",
    "\n",
    "residual_len = seqlen_k % residual_block_size\n",
    "residual     = residual_len > 0\n",
    "seqlen_k_pack = seqlen_k - residual_len\n",
    "\n",
    "cu_seqlens_k = torch.arange(0, (batch_size + 1) * seqlen_k_pack, seqlen_k_pack, \n",
    "                           dtype=torch.int32, device=device)\n",
    "\n",
    "# Initialize quantization tensors\n",
    "if quant_mode == \"k-channel\":\n",
    "    k_pack   = torch.zeros((batch_size, int(seqlen_k_pack // pack_nums), nheads_k, d),  dtype=torch.uint16, device=device)\n",
    "    k_params = torch.zeros((batch_size, int(seqlen_k_pack // group_size), nheads_k, d), dtype=torch.float32, device=device)\n",
    "else:\n",
    "    k_pack   = torch.zeros((batch_size, seqlen_k_pack, nheads_k, int(d // pack_nums)),  dtype=torch.uint16, device=device)\n",
    "    k_params = torch.zeros((batch_size, int(d // group_size), nheads_k, seqlen_k_pack), dtype=torch.float32, device=device)\n",
    "\n",
    "v_pack   = torch.zeros((batch_size, seqlen_k_pack, nheads_k, int(d // pack_nums)),  dtype=torch.uint16, device=device)\n",
    "v_params = torch.zeros((batch_size, int(d // group_size), nheads_k, seqlen_k_pack), dtype=torch.float32, device=device)\n",
    "\n",
    "# KV Cache Dynamic Cache\n",
    "past_key_value = DynamicCache()\n",
    "\n",
    "if residual:\n",
    "    k_state_residual = k_state[:, -residual_len:, :, :]\n",
    "    v_state_residual = v_state[:, -residual_len:, :, :]\n",
    "    k_state_past = k_state[:, :-residual_len, :, :]\n",
    "    v_state_past = v_state[:, :-residual_len, :, :]\n",
    "    past_key_value.update_residual(k_state_residual, v_state_residual, layer_idx)\n",
    "else:\n",
    "    k_state_past = k_state\n",
    "    v_state_past = v_state\n",
    "\n",
    "kvcache_pack_int(\n",
    "    k_state_past, k_pack, k_params,\n",
    "    v_state_past, v_pack, v_params,\n",
    "    None, # opt_block_table\n",
    "    cu_seqlens_k,              \n",
    "    seqlen_k_pack,\n",
    "    quant_mode,\n",
    "    group_size,\n",
    "    num_bits\n",
    ")\n",
    "past_key_value.update_pack(k_pack, k_params, v_pack, v_params, layer_idx)\n",
    "\n",
    "# self\n",
    "k_pack_new = torch.empty((batch_size, int(residual_block_size // pack_nums), nheads_k, k_pack.size(-1)),  dtype=torch.uint16, device=device)\n",
    "k_params_new = torch.empty((batch_size, int(residual_block_size // group_size), nheads_k, k_params.size(-1)), dtype=torch.float32, device=device)\n",
    "v_pack_new = torch.empty((batch_size, residual_block_size, nheads_k, v_pack.size(-1)), dtype=torch.uint16, device=device)\n",
    "v_params_new = torch.empty((batch_size, v_params.size(1), nheads_k, residual_block_size), dtype=torch.float32, device=device)\n",
    "\n",
    "####### Round 2-3 : Decode #######\n",
    "for round_idx in range(250):\n",
    "    k_new = torch.randn(batch_size, 1, nheads_k, d, device=device, dtype=dtype)\n",
    "    v_new = torch.randn(batch_size, 1, nheads_k, d, device=device, dtype=dtype)\n",
    "\n",
    "    # Get kv cache_pack\n",
    "    k_pack, k_params, v_pack, v_params = past_key_value.update_pack(None, None, None, None, layer_idx)\n",
    "\n",
    "    seqlen_pack = v_pack.shape[1]\n",
    "    seqlens_k = torch.full((batch_size,), seqlen_pack, dtype=torch.int32, device=device)\n",
    "\n",
    "    # Get kv cache_residual and append new kv\n",
    "    k_residual = torch.zeros((batch_size, residual_block_size, nheads_k, d), device=device, dtype=dtype)\n",
    "    v_residual = torch.zeros((batch_size, residual_block_size, nheads_k, d), device=device, dtype=dtype)\n",
    "    k_residual_cache, v_residual_cache = past_key_value.update_residual(k_new, v_new, layer_idx)\n",
    "\n",
    "    cur_residual_len = k_residual_cache.shape[1]\n",
    "\n",
    "    k_residual[:, :cur_residual_len, :, :] = k_residual_cache\n",
    "    v_residual[:, :cur_residual_len, :, :] = v_residual_cache\n",
    "\n",
    "    out_bitdecode, k_pack_new, k_params_new, v_pack_new, v_params_new = fwd_kvcache_int(\n",
    "        q,\n",
    "        k_pack, k_params, \n",
    "        v_pack, v_params,\n",
    "        k_residual, v_residual, seqlens_k, #seqlens_k\n",
    "        k_pack_new, k_params_new, v_pack_new, v_params_new,\n",
    "        None, # opt_block_table\n",
    "        sm_scale,\n",
    "        quant_mode, \n",
    "        group_size,\n",
    "        residual_block_size,\n",
    "        cur_residual_len, # new_lens\n",
    "        num_bits\n",
    "    )\n",
    "\n",
    "    if cur_residual_len == residual_block_size:\n",
    "        past_key_value.update_pack(k_pack_new, k_params_new, v_pack_new, v_params_new, layer_idx)\n",
    "        past_key_value.clear_residual(layer_idx)\n",
    "\n",
    "    k_state = torch.cat([k_state, k_new], dim=1)\n",
    "    v_state = torch.cat([v_state, v_new], dim=1)\n",
    "\n",
    "    out_ref = attention_ref(q, k_state, v_state)[0]\n",
    "    print(f\"Round {round_idx+2}: bitdecode vs pytorch: {(out_bitdecode - out_ref).abs().mean().item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bitdecode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
